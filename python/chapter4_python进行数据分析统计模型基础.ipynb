{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计模型\n",
    "由于一般的概率论难以描述现实中的现象。比如：食堂的菜好吃吗？那么明天该进什么货，那菜市场的价格变了很多怎么办呢？\n",
    "那么，使用现实世界对应的模型有助于我们`理解和预测现实事物`。\n",
    "\n",
    "## 一些概念\n",
    "数学模型：用数学式表达\n",
    "概率模型：用概率的语言表达\n",
    "\n",
    "那么统计模型：基于数据建立的概率模型。使用了概率论，并且经过了修正，那么也就是说更贴近实际。\n",
    "\n",
    "统计模型让数据分析有了很大的进步，勘称现代数据分析的标准基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模方法\n",
    "\n",
    "### 响应变量和解释变量等术语\n",
    "响应变量：根据某个因素而变化（相应）的变量。自变量\n",
    "解释变量：对关注的对象的变化进行解释的变量。因变量\n",
    "\n",
    "概率模型多记作：相应变量 ~ 解释变量。\n",
    "\n",
    "参数模型：用尽量少的参数表达的模型\n",
    "非参数模型：则相反了。\n",
    "\n",
    "线性模型，顾名思义，即对于一类可以用`矩阵形式`进行表达的模型的统称\n",
    "\n",
    "### 系数和权重\n",
    "模型中使用的参数叫做系数\n",
    "在机器学习中，模型的系数也叫做`权重`\n",
    "\n",
    "### 建模 = 模型选择 + 参数估计\n",
    "变量的选择：为模型选择解释变量\n",
    "\n",
    "#### 那么一般可分为\n",
    "-   通过假设-检验选择变量\n",
    "-   通过信息准则(Akaike Information Criterion, AIC)选择变量\n",
    "    -   AIC越小，模型越合适。\n",
    "\n",
    "### 模型评估\n",
    "评估模型的方法有两种：\n",
    "-   评估预测精度，精度越高，越准\n",
    "-   检验模型是否满足建模时所假设的条件\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据表示和模型名称\n",
    "\n",
    "### 正态线性模型\n",
    "假设响应变量服从正态分布的线性模型。\n",
    "\n",
    "#### 术语\n",
    "回归分析：解释变量为连续变量的模型。\n",
    "\n",
    "多元回归分析：含有多个解释变量的\n",
    "\n",
    "方差分析：解释变量为分类变量的模型。\n",
    "\n",
    "那么不符合正态分布的线性模型，叫做广义线性模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数估计\n",
    "参数估计是了解模型的一个重要一环。\n",
    "ps:其实用摸奖更容易描述。\n",
    "比如:打游戏的套路，一个游戏一旦出来久了，就会有各种攻略。\n",
    "就算我手残，反应慢，但是根据攻略，也会有收获。\n",
    "所以，这时候的攻略相当于模型，你的操作相当于输入的参数。\n",
    "练习操作，就有些调整参数的意味呢。\n",
    "\n",
    "那么，一般，我们会估计次序，模仿的程度，它可能是一套连招嘛。\n",
    "\n",
    "在统计学中，这个模仿的程度，叫似然(Likehood, θ)。\n",
    "它可以量化，看起来更精确。\n",
    "\n",
    "所以很多时候，你的操作行云流水，无可比拟时，如果用攻略来比照时，你的这个最大量，\n",
    "可能是偶然，但是要描述一般的表现怎么办呢？\n",
    "\n",
    "用最大似然值呗。\n",
    "\n",
    "### 最大似然法\n",
    "求得似然函数或对数似然最大值的参数，并且把参数作为参数估计值的方法。\n",
    "特点：整体状态比较封闭，一般用来估计大小，分量。\n",
    "\n",
    "从估计误差的角度来看，最大似然估计量表现的很好\n",
    "在所有具有渐进正态性估计量中，最大估计量的渐近方差最小，也就最接近有效估计量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数估计：最小化损失\n",
    "使用一定的标准(损失函数)，使得参数更准一些。\n",
    "\n",
    "#### 残差（residual)\n",
    "响应变量实际值与模型预测值之间的差。\n",
    "\n",
    "残差平方和\n",
    "\n",
    "其实，最大似然法和最小二乘法，在描述正态分布时，他们的极限值基本上相差不多。\n",
    "也就是说，二者在一定程度上会相互转化，成为同一把尺子。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测精度的评估和变量选择\n",
    "**拟合精度**：模型与已知数据的契合度\n",
    "**预测精度**：模型与未知数据的契合度\n",
    "\n",
    "过拟合：拟合程度很高，预测精度很低的现象。\n",
    "模型过于契合数据是过拟合的原因。\n",
    "\n",
    "泛化误差：预测值和未知数据之间的误差。\n",
    "训练集：用来估计参数的数据\n",
    "测试集：估计参数时，特意保留出一部分的数据。\n",
    "\n",
    "-   交叉验证（Cross Validaton, CV):\n",
    "    -   基于特定的法则，把数据分成了训练集和测试集，针对训练集评价模型预测精度。\n",
    "    -   K折交叉验证\n",
    "    -   由于交叉验证需要反复进行参数估计和精度评估，所以计算量巨大。\n",
    "\n",
    "-   赤池信息量准则(AIC)\n",
    "    -  AIC = -2 x ( 最大对数似然 - 参与估计的参数个数)\n",
    "    -  AIC 越小，模型越合适。\n",
    "       -  解释变量越多，对数似然越大，同时惩罚也越严重。\n",
    "       -  AIC 可以判断解释**增加的对数似然能否弥补更多的解释变量带来的缺点**？？。\n",
    "    -   相对熵\n",
    "        -   AIC的关注点是统计模型在预测上是否优秀。\n",
    "        -   统计模型的预测结果是一种概率分布，把它和数据真正服从的分布相比较，如何描述两者之间的差异呢？\n",
    "            -   衡量这个差异的指标：**相对熵**。\n",
    "\n",
    "这里涉及很多数学上的东西，暂时且放过。\n",
    "用变量选择还是假设检验, AIC主要是为了提高预测精度而设计的指标,\n",
    "AIC的用途是借助已知数据让模型的预测精度最高."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
